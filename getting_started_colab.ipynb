{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7",
      "language": "python",
      "name": "python3.7"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "getting_started.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DjRcQLs_3Cb"
      },
      "source": [
        "# Getting started with ReColorAdv\n",
        "This file contains instructions for experimenting with the ReColorAdv attack, by itself and combined with other attacks. This tutorial is based on the [first tutorial](https://github.com/revbucket/mister_ed/blob/master/notebooks/tutorial_1.ipynb) of `mister_ed`. See the README to make sure all dependencies are installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doj2ElNu_3Cc"
      },
      "source": [
        "## Imports\n",
        "First let's make sure that you can import everything you need:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pWDR8eO_3Ch"
      },
      "source": [
        "!pip install recoloradv\n",
        "\n",
        "# EXTERNAL LIBRARIES\n",
        "import numpy as np \n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim \n",
        "\n",
        "# mister_ed\n",
        "import recoloradv.mister_ed.loss_functions as lf \n",
        "import recoloradv.mister_ed.utils.pytorch_utils as utils\n",
        "import recoloradv.mister_ed.utils.image_utils as img_utils\n",
        "import recoloradv.mister_ed.cifar10.cifar_loader as cifar_loader\n",
        "import recoloradv.mister_ed.cifar10.cifar_resnets as cifar_resnets\n",
        "import recoloradv.mister_ed.adversarial_training as advtrain\n",
        "import recoloradv.mister_ed.utils.checkpoints as checkpoints\n",
        "import recoloradv.mister_ed.adversarial_perturbations as ap \n",
        "import recoloradv.mister_ed.adversarial_attacks as aa\n",
        "import recoloradv.mister_ed.spatial_transformers as st\n",
        "import recoloradv.mister_ed.config as config\n",
        "\n",
        "# ReColorAdv\n",
        "import recoloradv.perturbations as pt\n",
        "import recoloradv.color_transformers as ct\n",
        "import recoloradv.color_spaces as cs\n",
        "from recoloradv import norms\n",
        "from recoloradv.utils import load_pretrained_cifar10_model, get_attack_from_name\n",
        "\n",
        "# Set up CIFAR-10\n",
        "!python -m recoloradv.mister_ed.scripts.setup_cifar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKNIJA3r_3Ck"
      },
      "source": [
        "#  Generating adversarial examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK14jDw-_3Cl"
      },
      "source": [
        "Here, we will demonstrate how to generate a single minibatch of adversarial examples using ReColorAdv on CIFAR-10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Y-v7nu_3Cl"
      },
      "source": [
        "To set up, let's start by collecting a minibatch worth of data and loading up our classifier to attack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoqMhAhp_3Cm"
      },
      "source": [
        "cifar_valset = cifar_loader.load_cifar_data('val', batch_size=16)\n",
        "examples, labels = next(iter(cifar_valset))\n",
        "\n",
        "model, normalizer = cifar_loader.load_pretrained_cifar_resnet(return_normalizer=True)\n",
        "\n",
        "if utils.use_gpu():\n",
        "    examples = examples.cuda()\n",
        "    labels = labels.cuda() \n",
        "    model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgaMv0et_3Co"
      },
      "source": [
        "Let's take a look at what our original images look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnjBiqHr_3Cs"
      },
      "source": [
        "img_utils.show_images(examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sq9mTRs_3Cw"
      },
      "source": [
        "## ReColorAdv\n",
        "Now let's attack all of these examples with a ReColorAdv attack that changes every pixel using the same function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc48oTVS_3Cw"
      },
      "source": [
        "# This threat model defines the regularization parameters of the attack.\n",
        "recoloradv_threat = ap.ThreatModel(pt.ReColorAdv, {\n",
        "    'xform_class': ct.FullSpatial, \n",
        "    'cspace': cs.CIELUVColorSpace(), # controls the color space used\n",
        "    'lp_style': 'inf',\n",
        "    'lp_bound': [0.06, 0.06, 0.06],  # [epsilon_1, epsilon_2, epsilon_3]\n",
        "    'xform_params': {\n",
        "      'resolution_x': 16,            # R_1\n",
        "      'resolution_y': 32,            # R_2\n",
        "      'resolution_z': 32,            # R_3\n",
        "    },\n",
        "    'use_smooth_loss': True,\n",
        "})\n",
        "\n",
        "\n",
        "# Now, we define the main optimization term (the Carlini & Wagner f6 loss).\n",
        "adv_loss = lf.CWLossF6(model, normalizer)\n",
        "\n",
        "# We also need the smoothness loss.\n",
        "smooth_loss = lf.PerturbationNormLoss(lp=2)\n",
        "\n",
        "# We combine them with a RegularizedLoss object.\n",
        "attack_loss = lf.RegularizedLoss({'adv': adv_loss, 'smooth': smooth_loss}, \n",
        "                                 {'adv': 1.0,      'smooth': 0.05},   # lambda = 0.05\n",
        "                                 negate=True) # Need this true for PGD type attacks\n",
        "\n",
        "# PGD is used to optimize the above loss.\n",
        "pgd_attack_obj = aa.PGD(model, normalizer, recoloradv_threat, attack_loss)\n",
        "\n",
        "# We run the attack for 10 iterations at learning rate 0.01.\n",
        "perturbation = pgd_attack_obj.attack(examples, labels, num_iterations=10, signed=False, \n",
        "                                     optimizer=optim.Adam, optimizer_kwargs={'lr': 0.01},\n",
        "                                     verbose=True)\n",
        "\n",
        "# Now, we can collect the successful adversarial examples and display them.\n",
        "successful_advs, successful_origs = perturbation.collect_successful(model, normalizer)\n",
        "successful_diffs = ((successful_advs - successful_origs) * 3 + 0.5).clamp(0, 1)\n",
        "img_utils.show_images([successful_origs, successful_advs, successful_diffs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VklpLYLJ_3Cz"
      },
      "source": [
        "In the above image, the first row is the original images; the second row is the adversarial examples; and the third row is the magnified difference between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3jBP6Q8_3Cz"
      },
      "source": [
        "## Combined Attacks\n",
        "Now that we've seen how to use the ReColorAdv attack, we can combine it with an additive delta attack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KghrZOmv_3C0"
      },
      "source": [
        "# First, we define the additive threat model.\n",
        "additive_threat = ap.ThreatModel(ap.DeltaAddition, {\n",
        "   'lp_style': 'inf', \n",
        "   'lp_bound': 0.03,\n",
        "})\n",
        "\n",
        "# Combine it with the ReColorAdv functional threat model.\n",
        "combined_threat = ap.ThreatModel(\n",
        "    ap.SequentialPerturbation, \n",
        "    [recoloradv_threat, additive_threat],\n",
        "    ap.PerturbationParameters(norm_weights=[1.0, 0.0]),\n",
        ")\n",
        "\n",
        "# Again, define the optimization terms.\n",
        "adv_loss = lf.CWLossF6(model, normalizer)\n",
        "smooth_loss = lf.PerturbationNormLoss(lp=2)\n",
        "attack_loss = lf.RegularizedLoss({'adv': adv_loss, 'smooth': smooth_loss}, \n",
        "                                 {'adv': 1.0,      'smooth': 0.05},\n",
        "                                 negate=True) # Need this true for PGD type attacks\n",
        "\n",
        "# Setup and run PGD over both perturbations at once.\n",
        "pgd_attack_obj = aa.PGD(model, normalizer, combined_threat, attack_loss)\n",
        "perturbation = pgd_attack_obj.attack(examples, labels, num_iterations=10, signed=False, \n",
        "                                     optimizer=optim.Adam, optimizer_kwargs={'lr': 0.01},\n",
        "                                     verbose=True)\n",
        "\n",
        "# Display the successful adversarial examples.\n",
        "successful_advs, successful_origs = perturbation.collect_successful(model, normalizer)\n",
        "successful_diffs = ((successful_advs - successful_origs) * 3 + 0.5).clamp(0, 1)\n",
        "img_utils.show_images([successful_origs, successful_advs, successful_diffs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsMeTfnX_3C4"
      },
      "source": [
        "Note that the resulting adversarial examples have been both recolored using ReColorAdv and had some additive adversarial noise applied from the delta attack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9kNWvvC_3C4"
      },
      "source": [
        "## Prebuilt Attacks\n",
        "The convenience function `get_attack_from_name` allows you to easily instantiate one of the attacks used in the paper. For instance, to use the combined ReColorAdv, StAdv, and delta attacks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QwYSgtd_3C5"
      },
      "source": [
        "attack = get_attack_from_name('recoloradv+stadv+delta', model, normalizer, verbose=True)\n",
        "perturbation = attack.attack(examples, labels)\n",
        "\n",
        "# Display the successful adversarial examples.\n",
        "successful_advs, successful_origs = perturbation.collect_successful(model, normalizer)\n",
        "successful_diffs = ((successful_advs - successful_origs) * 3 + 0.5).clamp(0, 1)\n",
        "img_utils.show_images([successful_origs, successful_advs, successful_diffs])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}