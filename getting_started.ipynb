{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with ReColorAdv\n",
    "This file contains instructions for experimenting with the ReColorAdv attack, by itself and combined with other attacks. This tutorial is based on the [first tutorial](https://github.com/revbucket/mister_ed/blob/master/notebooks/tutorial_1.ipynb) of `mister_ed`. See the README to make sure all dependencies are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First let's make sure that you can import everything you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTERNAL LIBRARIES\n",
    "import numpy as np \n",
    "import scipy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mister_ed\n",
    "import recoloradv.mister_ed.loss_functions as lf \n",
    "import recoloradv.mister_ed.utils.pytorch_utils as utils\n",
    "import recoloradv.mister_ed.utils.image_utils as img_utils\n",
    "import recoloradv.mister_ed.cifar10.cifar_loader as cifar_loader\n",
    "import recoloradv.mister_ed.cifar10.cifar_resnets as cifar_resnets\n",
    "import recoloradv.mister_ed.adversarial_training as advtrain\n",
    "import recoloradv.mister_ed.utils.checkpoints as checkpoints\n",
    "import recoloradv.mister_ed.adversarial_perturbations as ap \n",
    "import recoloradv.mister_ed.adversarial_attacks as aa\n",
    "import recoloradv.mister_ed.spatial_transformers as st\n",
    "\n",
    "# ReColorAdv\n",
    "import recoloradv.perturbations as pt\n",
    "import recoloradv.color_transformers as ct\n",
    "import recoloradv.color_spaces as cs\n",
    "from recoloradv import norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure that you have CIFAR-10 data loaded and a pretrained classifier running. If the following block fails, then make sure you've run the setup script:\n",
    "\n",
    "```python -m recoloradv.mister_ed.scripts.setup_cifar```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to ensure cifar 10 data and pretrained classifiers are loaded \n",
    "cifar_valset = cifar_loader.load_cifar_data('val')\n",
    "model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=32, return_normalizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generating adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will demonstrate how to generate a single minibatch of adversarial examples using ReColorAdv on CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up, let's start by collecting a minibatch worth of data and loading up our classifier to attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_valset = cifar_loader.load_cifar_data('val', batch_size=16)\n",
    "examples, labels = next(iter(cifar_valset))\n",
    "\n",
    "model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=32, return_normalizer=True)\n",
    "\n",
    "if utils.use_gpu():\n",
    "    examples = examples.cuda()\n",
    "    labels = labels.cuda() \n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what our original images look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_utils.show_images(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReColorAdv\n",
    "Now let's attack all of these examples with a ReColorAdv attack that changes every pixel using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This threat model defines the regularization parameters of the attack.\n",
    "recoloradv_threat = ap.ThreatModel(pt.ReColorAdv, {\n",
    "    'xform_class': ct.FullSpatial, \n",
    "    'cspace': cs.CIELUVColorSpace(), # controls the color space used\n",
    "    'lp_style': 'inf',\n",
    "    'lp_bound': [0.06, 0.06, 0.06],  # [epsilon_1, epsilon_2, epsilon_3]\n",
    "    'xform_params': {\n",
    "      'resolution_x': 16,            # R_1\n",
    "      'resolution_y': 32,            # R_2\n",
    "      'resolution_z': 32,            # R_3\n",
    "    },\n",
    "    'use_smooth_loss': True,\n",
    "})\n",
    "\n",
    "\n",
    "# Now, we define the main optimization term (the Carlini & Wagner f6 loss).\n",
    "adv_loss = lf.CWLossF6(model, normalizer)\n",
    "\n",
    "# We also need the smoothness loss.\n",
    "smooth_loss = lf.PerturbationNormLoss(lp=2)\n",
    "\n",
    "# We combine them with a RegularizedLoss object.\n",
    "attack_loss = lf.RegularizedLoss({'adv': adv_loss, 'smooth': smooth_loss}, \n",
    "                                 {'adv': 1.0,      'smooth': 0.05},   # lambda = 0.05\n",
    "                                 negate=True) # Need this true for PGD type attacks\n",
    "\n",
    "# PGD is used to optimize the above loss.\n",
    "pgd_attack_obj = aa.PGD(model, normalizer, recoloradv_threat, attack_loss)\n",
    "\n",
    "# We run the attack for 10 iterations at learning rate 0.01.\n",
    "perturbation = pgd_attack_obj.attack(examples, labels, num_iterations=10, signed=False, \n",
    "                                     optimizer=optim.Adam, optimizer_kwargs={'lr': 0.01},\n",
    "                                     verbose=True)\n",
    "\n",
    "# Now, we can collect the successful adversarial examples and display them.\n",
    "successful_advs, successful_origs = perturbation.collect_successful(model, normalizer)\n",
    "successful_diffs = ((successful_advs - successful_origs) * 3 + 0.5).clamp(0, 1)\n",
    "img_utils.show_images([successful_origs, successful_advs, successful_diffs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above image, the first row is the original images; the second row is the adversarial examples; and the third row is the magnified difference between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Attacks\n",
    "Now that we've seen how to use the ReColorAdv attack, we can combine it with an additive delta attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we define the additive threat model.\n",
    "additive_threat = ap.ThreatModel(ap.DeltaAddition, {\n",
    "   'lp_style': 'inf', \n",
    "   'lp_bound': 0.03,\n",
    "})\n",
    "\n",
    "# Combine it with the ReColorAdv functional threat model.\n",
    "combined_threat = ap.ThreatModel(\n",
    "    ap.SequentialPerturbation, \n",
    "    [recoloradv_threat, additive_threat],\n",
    "    ap.PerturbationParameters(norm_weights=[1.0, 0.0]),\n",
    ")\n",
    "\n",
    "# Again, define the optimization terms.\n",
    "adv_loss = lf.CWLossF6(model, normalizer)\n",
    "smooth_loss = lf.PerturbationNormLoss(lp=2)\n",
    "attack_loss = lf.RegularizedLoss({'adv': adv_loss, 'smooth': smooth_loss}, \n",
    "                                 {'adv': 1.0,      'smooth': 0.05},\n",
    "                                 negate=True) # Need this true for PGD type attacks\n",
    "\n",
    "# Setup and run PGD over both perturbations at once.\n",
    "pgd_attack_obj = aa.PGD(model, normalizer, combined_threat, attack_loss)\n",
    "perturbation = pgd_attack_obj.attack(examples, labels, num_iterations=10, signed=False, \n",
    "                                     optimizer=optim.Adam, optimizer_kwargs={'lr': 0.01},\n",
    "                                     verbose=True)\n",
    "\n",
    "# Display the successful adversarial examples.\n",
    "successful_advs, successful_origs = perturbation.collect_successful(model, normalizer)\n",
    "successful_diffs = ((successful_advs - successful_origs) * 3 + 0.5).clamp(0, 1)\n",
    "img_utils.show_images([successful_origs, successful_advs, successful_diffs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resulting adversarial examples have been both recolored using ReColorAdv and had some additive adversarial noise applied from the delta attack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
